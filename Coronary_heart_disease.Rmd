---
title: "STAT 632 Project"
author: "James Hopham"
date: "2023-04-19"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r}
library(tidyverse)
library(MASS)
library(faraway)
library(pROC)
library(caret)
library(dplyr)
```

## Data Processing

```{r}
#load data
heart_disease<-read_csv("train.csv")

head(heart_disease)

dim(heart_disease)

#remove na values

heart_disease_final<- na.omit(heart_disease)

dim(heart_disease_final)

head(heart_disease_final)


heart_disease_final$age

heart_disease_final2 <- heart_disease_final[,-c(1,7,8,10)]

head(heart_disease_final2)

#split into train and test datasets 

set.seed(999) # set seed for reproducibility
n <- nrow(heart_disease_final2); n

floor<-floor(0.6*n) #round down to nearest integer

# randomly sample 60% of rows for training set
train <- sample(1:n, floor)

```

```{r}


summary(heart_disease_final2)
```

## Initial Model

```{r}
#train initial model including all predictors
glm_train <- glm(TenYearCHD ~ ., data=heart_disease_final2, subset = train, family = binomial)

summary(glm_train)
```

significant predictors: age, sex, cigs per day, total cholesterol, sys BP, dia BP, glucose

## Variable Selection

```{r}
#correct for collinearity among predictors

library(faraway) # to use vif() function

round(vif(glm_train), 2)
```

```{r}
glm_train_remove_final_version1 <- glm(TenYearCHD ~ heartRate + BPMeds  + diabetes  + prevalentStroke, data=heart_disease_final, subset = train, family = binomial) 

round(vif(glm_train_remove_final_version1), 2)
```

```{r}
glm_train_remove_final_version2 <- glm(TenYearCHD ~ sysBP + BPMeds  + diabetes  + prevalentStroke, data=heart_disease_final, subset = train, family = binomial) 

```

Based on overall vif scores from removing predictors, along with selecting predictors based on relevant research on connections on these variables we ultimately decide to keep the first final version since blood pressure medication will inevitably lower systolic blood pressure.

## Stepwise Selection

```{r}
#use step() function to implement backwards stepwise selection using AIC

#specify full model
glm5 <- glm_train

glm_sel <- step(glm5) #treated as glm() object so cannot use glm_sel for predict function

summary(glm_sel)

AIC(glm5, glm_sel)
```

## Initial Model From Step Wise Selection Tested 

```{r}
# subset data frame for testing observations
heart_disease_test <- heart_disease_final2[-train, ]

# make predictions for probabilities on test set
probs_test <- predict(glm_sel, newdata = heart_disease_test, type = "response")
```

```{r}
#We can use a 0.5 probability threshold to classify points in the test set. If the predicted probability is greater than 0.5, classify as a (1). Otherwise, if the predicted probability is less than 0.5, classify as (0).

length(probs_test)

preds_test <- rep(0, 1171)

preds_test[probs_test > 0.5] <- 1

head(probs_test)

head(preds_test) # everything now binomial 0 or 1
```

```{r}
#confusion matrix - tabulates predicted vs actual results 

# make confusion matrix
tb <- table(prediction = preds_test, actual = heart_disease_test$TenYearCHD)

addmargins(tb) #the model correctly predicted Trump losing in 125 counties, and correctly predicted Trump winning in 763 counties.

#compute metrics (accuracy, sensitivity, specifity) on test set

# Accuracy (percent correctly classified)
(tb[1,1] + tb[2,2]) / 1171

# Sensitivity (percent of Trump wins (1) correctly classified)
tb[2,2] / 171

#Specificity (percent of Trump losses (0) correctly classified)
tb[1,1] / 1000
```

```{r}
#plot ROC Curve
library(pROC)

roc_obj <- roc(heart_disease_test$TenYearCHD, probs_test)

plot(1 - roc_obj$specificities, roc_obj$sensitivities, type="l",
     xlab = "1 - Specificity",
     ylab = "Sensitivity")

# plot red point corresponding to 0.5 threshold:
points(x = 9/1000, y = 20/171, col="red", pch=19)
abline(0, 1, lty=2) # 1-1 line
```

```{r}
auc(roc_obj)
```

## Final Model

```{r}
glm_train_remove_final_version3 <- glm(TenYearCHD ~ age + sex + cigsPerDay + totChol +prevalentHyp + glucose + sysBP, data=heart_disease_final2, subset = train, family = binomial)

summary(glm_train_remove_final_version3)

confint(glm_train_remove_final_version3)
```

## Cross Validation

```{r}
# subset data frame for testing observations
heart_disease_test <- heart_disease_final2[-train, ]

# make predictions for probabilities on test set
probs_test <- predict(glm_train_remove_final_version3, newdata = heart_disease_test, type = "response")
```

```{r}
#We can use a 0.5 probability threshold to classify points in the test set. If the predicted probability is greater than 0.5, classify as a (1). Otherwise, if the predicted probability is less than 0.5, classify as (0).

length(probs_test)

preds_test <- rep(0, 1171)

preds_test[probs_test > 0.2] <- 1

head(probs_test)

head(preds_test) # everything now binomial 0 or 1
```

```{r}
#confusion matrix - tabulates predicted vs actual results 

# make confusion matrix
tb <- table(prediction = preds_test, actual = heart_disease_test$TenYearCHD)

addmargins(tb) #the model correctly predicted Trump losing in 125 counties, and correctly predicted Trump winning in 763 counties.

#compute metrics (accuracy, sensitivity, specifity) on test set

# Accuracy (percent correctly classified)
(tb[1,1] + tb[2,2]) / 1171

# Sensitivity (percent of Trump wins (1) correctly classified)
tb[2,2] / 171

#Specificity (percent of Trump losses (0) correctly classified)
tb[1,1] / 1000
```

```{r}
#plot ROC Curve
library(pROC)

roc_obj <- roc(heart_disease_test$TenYearCHD, probs_test)

plot(1 - roc_obj$specificities, roc_obj$sensitivities, type="l",
     xlab = "1 - Specificity",
     ylab = "Sensitivity")

# plot red point corresponding to 0.5 threshold:
points(x = 232/1000, y = 94/171, col="red", pch=19)
abline(0, 1, lty=2) # 1-1 line
```

```{r}
auc(roc_obj)
```

## Random Forest

```{r}
library(tidymodels)

set.seed(364)
n <- nrow(heart_disease_final2)
heart_data_parts <- heart_disease_final2 %>%
  initial_split(prop = 0.6)

train <- heart_data_parts %>% 
  training()%>%
  mutate(TenYearCHD = factor(TenYearCHD))

test <- heart_data_parts %>% 
  testing()%>%
  mutate(TenYearCHD = factor(TenYearCHD))

form <- as.formula(
  "TenYearCHD ~ age + sex + cigsPerDay + totChol +prevalentHyp + glucose + sysBP"
)
```

```{r}
heart_disease_train_ranger <- rand_forest(trees = 100) %>%
set_engine("ranger") %>%
set_mode("classification") %>%
fit(TenYearCHD ~ age + sex + cigsPerDay + totChol +prevalentHyp + glucose + sysBP, data = train)
```

```{r}
predictions<- predict(heart_disease_train_ranger, train)
```

```{r}
heart_disease_train_ranger %>%
  predict(test) %>%
   bind_cols(test)
```

```{r}
heart_disease_train_ranger %>%
predict(test) %>%
bind_cols(test) %>%
metrics(truth = TenYearCHD, estimate = .pred_class)
```

```{r}
heart_disease_train_ranger %>%
predict(test) %>%
bind_cols(test) %>%
conf_mat(truth = TenYearCHD, estimate = .pred_class)
```

```{r}
heart_disease_train_ranger %>%
predict(test, type = "prob") %>%
bind_cols(test) %>%
roc_curve(TenYearCHD, .pred_0) %>%
autoplot()

```

```{r}
roc_auc<- heart_disease_train_ranger %>%
predict(test, type = "prob") %>%
bind_cols(test) %>%
roc_auc(TenYearCHD, .pred_0)

roc_auc
```
